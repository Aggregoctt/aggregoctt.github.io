---
author: Maxwell Zeff
canonical_url: https://techcrunch.com/2025/05/15/anthropics-lawyer-was-forced-to-apologize-after-claude-hallucinated-a-legal-citation/
date: '2025-05-15T19:37:53'
excerpt: A lawyer representing Anthropic admitted to using an erroneous citation created
  by the company&#8217;s Claude AI chatbot in its ongoing legal battle with music
  publishers, according to a filing made in a Northern California court on Thursday.
  Claude hallucinated the citation with &#8220;an inaccurate title and inaccurate
  authors,&#8221; Anthropic says in the filing, first reported [&#8230;]
image: assets/media/awMAIXE05MHxsQpJ6YkjNA-_EflGAhMEmbv0MyzjMqkvw.webp
source: techcrunch
tags:
- AI
- Anthropic
- Claude
title: Anthropicâ€™s lawyer was forced to apologize after Claude hallucinated a legal
  citation
---
<div>
<p id="speakable-summary" class="wp-block-paragraph">A lawyer representing Anthropic admitted to using an erroneous citation created by the company&#8217;s Claude AI chatbot in its ongoing legal battle with music publishers, according to a <a href="https://www.documentcloud.org/documents/25943457-anthropic-515-filing/#document/p1" target="_blank" rel="noreferrer noopener nofollow">filing</a> made in a Northern California court on Thursday.</p>

<p class="wp-block-paragraph">Claude hallucinated the citation with &#8220;an inaccurate title and inaccurate authors,&#8221; Anthropic says in the filing, <a href="https://news.bloomberglaw.com/ip-law/anthropic-admits-ai-caused-miscite-in-expert-report-in-ip-suit" target="_blank" rel="noreferrer noopener nofollow">first reported by Bloomberg</a>. Anthropic&#8217;s lawyers explain that their &#8220;manual citation check&#8221; did not catch it, nor several other errors that were caused by Claude&#8217;s hallucinations.</p>

 


 


<p class="wp-block-paragraph">Anthropic apologized for the error and called it &#8220;an honest citation mistake and not a fabrication of authority.&#8221;</p>

<p class="wp-block-paragraph">Earlier this week, lawyers representing Universal Music Group and other music publishers accused Anthropic&#8217;s expert witness &#8212; one of the company&#8217;s employees, Olivia Chen &#8212; of <a href="https://www.reuters.com/legal/litigation/anthropic-expert-accused-using-ai-fabricated-source-copyright-case-2025-05-13/" target="_blank" rel="noreferrer noopener nofollow">using Claude to cite fake articles in her testimony</a>. Federal judge, Susan van Keulen, then ordered Anthropic to respond to these allegations.</p>

<p class="wp-block-paragraph">The music publishers&#8217; lawsuit is one of several disputes between copyright owners and tech companies over the supposed misuse of their work to create generative AI tools.</p>

<p class="wp-block-paragraph">This is the latest instance of lawyers using AI in court and then regretting the decision. Earlier this week, a California judge slammed a pair of law firms for submitting &#8220;<a href="https://www.theverge.com/news/666443/judge-slams-lawyers-ai-bogus-research" target="_blank" rel="noreferrer noopener nofollow">bogus AI-generated research</a>&#8221; in his court. In January, an Australian lawyer was <a href="https://www.theguardian.com/australia-news/2025/feb/01/australian-lawyer-caught-using-chatgpt-filed-court-documents-referencing-non-existent-cases" target="_blank" rel="noreferrer noopener nofollow">caught using ChatGPT in the preparation of court documents</a> and the chatbot produced faulty citations.</p>

 
 

 


			

			</div>