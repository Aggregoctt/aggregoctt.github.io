---
author: Julie Bort
canonical_url: https://techcrunch.com/2025/05/15/sam-altmans-goal-for-chatgpt-to-remember-your-whole-life-is-both-exciting-and-disturbing/
date: '2025-05-15T23:05:45'
excerpt: OpenAI CEO Sam Altman laid out a big vision for the future of ChatGPT at
  an AI event hosted by VC firm Sequoia earlier this month.&#160; When asked by one
  attendee about how ChatGPT can become more personalized, Altman replied that he
  eventually wants the model to document and remember everything in a person’s life.
  [&#8230;]
image: assets/media/ELdeNN0IyFJUItzXZcprlQ-jHmW0uE8lID2R2WyY7838Q.webp
source: techcrunch
tags:
- AI
- TC
- ChatGPT
- sam altman
- Sequoia Capital
title: Sam Altman’s goal for ChatGPT to remember ‘your whole life’ is both exciting
  and disturbing
---
<div>
<p id="speakable-summary" class="wp-block-paragraph">OpenAI CEO Sam Altman laid out a big vision for the future of ChatGPT at an AI event hosted by VC firm <a rel="nofollow" href="https://www.youtube.com/watch?v=ctcMA6chfDY">Sequoia earlier this month.&#160;</a></p>

<p class="wp-block-paragraph">When asked by one attendee about how ChatGPT can become more personalized, Altman replied that he eventually wants the model to document and remember everything in a person&#8217;s life.</p>

 


 


<p class="wp-block-paragraph">The ideal, he said, is a &#8220;very tiny reasoning model with a trillion tokens of context that you put your whole life into.&#8221;</p>

<p class="wp-block-paragraph">&#8220;This model can reason across your whole context and do it efficiently. And every conversation you&#8217;ve ever had in your life, every book you&#8217;ve ever read, every email you&#8217;ve ever read, everything you&#8217;ve ever looked at is in there, plus connected to all your data from other sources. And your life just keeps appending to the context,&#8221; he described.</p>

<p class="wp-block-paragraph">&#8220;Your company just does the same thing for all your company&#8217;s data,&#8221; he added.</p>

<p class="wp-block-paragraph">Altman may have some data-driven reason to think this is ChatGPT&#8217;s natural future. In that same discussion, when asked for cool ways young people use ChatGPT, he said, &#8220;People in college use it as an operating system.&#8221; They upload files, connect data sources, and then use &#8220;complex prompts&#8221; against that data.</p>

<p class="wp-block-paragraph">Additionally, with <a rel="nofollow" href="https://help.openai.com/en/articles/8590148-memory-faq">ChatGPT&#8217;s memory options</a> &#8212; which can use previous chats and memorized facts as context &#8212; he said one trend he&#8217;s noticed is that young people &#8220;don&#8217;t really make life decisions without asking ChatGPT.&#8221;&#160;</p>
 

<p class="wp-block-paragraph">&#8220;A gross oversimplification is: older people use ChatGPT as, like, a Google replacement,&#8221; he said. &#8220;People in their 20s and 30s use it like a life advisor.&#8221;</p>

<p class="wp-block-paragraph">It&#8217;s not much of a leap to see how ChatGPT could become an all-knowing AI system. Paired with the agents the Valley is currently trying to build, that&#8217;s an exciting future to think about.&#160;</p>

<p class="wp-block-paragraph">Imagine your AI automatically scheduling your car&#8217;s oil changes and reminding you; planning the travel necessary for an out-of-town wedding and ordering the gift from the registry; or pre-ordering the next volume of the book series you&#8217;ve been reading for years.</p>

 


 


<p class="wp-block-paragraph">But the scary part? How much should we trust a Big Tech for-profit company to know everything about our lives? These are companies that don&#8217;t always behave in model ways.</p>

<p class="wp-block-paragraph">Google, which began life with the motto &#8220;don&#8217;t be evil&#8221; <a href="https://techcrunch.com/2025/04/17/judge-rules-google-illegally-monopolized-ad-tech-opening-door-to-potential-breakup/">lost a lawsuit in the U.S. that accused it</a> of engaging in anticompetitive, monopolistic behavior.&#160;</p>

<p class="wp-block-paragraph">Chatbots can be trained to respond in politically motivated ways. Not only have Chinese bots been found to <a href="https://techcrunch.com/2025/03/26/leaked-data-exposes-a-chinese-ai-censorship-machine/">comply with China&#8217;s censorship requirements</a> but xAI&#8217;s chatbot Grok this week was randomly <a href="https://techcrunch.com/2025/05/14/grok-is-unpromptedly-telling-x-users-about-south-african-genocide/">discussing a South African &#8220;white genocide&#8221;</a> when people asked it completely unrelated questions. The behavior, <a rel="nofollow" href="https://x.com/luxeprogressive/status/1922851076266508529">many noted</a>, implied intentional manipulation of its response engine at the command of its South African-born founder, Elon Musk.</p>

<p class="wp-block-paragraph">Last month, ChatGPT became so agreeable it <a href="https://techcrunch.com/2025/04/29/openai-explains-why-chatgpt-became-too-sycophantic/">was downright sycophantic</a>. Users began sharing screenshots of the bot applauding problematic, even <a rel="nofollow" href="https://x.com/fabianstelzer/status/1916372374091423984">dangerous</a> <a rel="nofollow" href="https://x.com/thinkbuildnext/status/1916250081579217243">decisions</a> and <a rel="nofollow" href="https://x.com/ai_for_success/status/1916556522571604264">ideas</a>. Altman quickly responded by promising the team had fixed the tweak that caused the problem.</p>

<p class="wp-block-paragraph">Even the best, most reliable models still just outright <a rel="nofollow" href="https://github.com/vectara/hallucination-leaderboard">make stuff up from time to time.&#160;</a></p>

<p class="wp-block-paragraph">So, having an all-knowing AI assistant could help our lives in ways we can only begin to see.&#160; But given big tech&#8217;s long history of iffy behavior, that&#8217;s also a situation ripe for misuse.</p>


			

			</div>