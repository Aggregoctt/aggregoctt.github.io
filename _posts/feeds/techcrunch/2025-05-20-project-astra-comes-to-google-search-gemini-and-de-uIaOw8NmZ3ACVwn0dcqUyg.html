---
author: Maxwell Zeff
canonical_url: https://techcrunch.com/2025/05/20/project-astra-comes-to-google-search-gemini-and-developers/
date: '2025-05-20T17:45:00'
excerpt: Google announced on Tuesday during Google I/O 2025 that Project Astra — the
  company&#8217;s low latency, multimodal AI experience — will power an array of new
  experiences in Search, the Gemini AI app, and products from third-party developers.
  Most notably, Project Astra is powering a new Search Live feature in Google Search.
  When using AI [&#8230;]
image: assets/media/uIaOw8NmZ3ACVwn0dcqUyg-3uaswvk0tLz0X5asz9yK7w.webp
source: techcrunch
tags:
- AI
- Google I/O
- project astra
title: Project Astra comes to Google Search, Gemini, and developers
---
<div>
<p id="speakable-summary" class="wp-block-paragraph">Google announced on Tuesday during <a href="https://techcrunch.com/storyline/google-i-o-2025-live-coverage-gemini-android-16-updates-and-more/">Google I/O 2025</a> that Project Astra &#8212; <a href="https://techcrunch.com/2024/12/12/google-wants-to-sell-those-project-astra-ar-glasses-some-day-but-it-wont-be-today/">the company&#8217;s low latency, multimodal AI experience</a> &#8212; will power an array of new experiences in Search, the Gemini AI app, and products from third-party developers.</p>

<p class="wp-block-paragraph">Most notably, Project Astra is powering a new Search Live feature in Google Search. When using AI Mode, Google&#8217;s AI-powered search feature, or Lens, the company&#8217;s visual search feature, users can click the &#8220;Live&#8221; button to ask questions about what they&#8217;re seeing through their smartphone&#8217;s camera. Project Astra streams live video and audio into an AI model, and responds with answers to users&#8217; questions with little to no latency.</p>

 


 


<p class="wp-block-paragraph">First unveiled at Google I/O 2024 through a <a href="https://techcrunch.com/2024/05/14/googles-gemini-updates-how-project-astra-is-powering-some-of-i-os-big-reveals/">viral smart glasses demo,</a> Project Astra was born out of Google DeepMind as a way to showcase nearly real-time, multimodal AI capabilities. Google now says it&#8217;s building those Project Astra glasses with partners including Samsung and Warby Parker, but the company doesn&#8217;t have a set launch date yet. What the company does have is a variety of Project Astra-powered features for consumers and developers. </p>

<p class="wp-block-paragraph">Google says Project Astra is powering a new feature in its Live API, a developer-facing endpoint that enables low-latency voice interactions with Gemini. Starting Tuesday, developers can build experiences that support audio and visual input, and native audio output &#8212; much like Project Astra. Google says the updated Live API also has enhanced emotion detection, meaning the AI model will respond more appropriately, and includes thinking capabilities from Gemini&#8217;s reasoning AI models.</p>

<p class="wp-block-paragraph">In the Gemini app, Google says Project Astra&#8217;s real-time video and screen-sharing capabilities are coming to all users. While Project Astra already powers Gemini Live&#8217;s low-latency conversations, this visual input was previously reserved for paid subscribers.</p>

<p class="wp-block-paragraph">Google seems confident that Project Astra is the future for many of its products, and even can power an entirely new product category: smart glasses. While that may be true, Google still hasn&#8217;t set a launch date for the Project Astra smart glasses it demoed last year. The company has offered a few more details on what those smart glasses will look like, but they still seem far from reality. </p>


			

			</div>