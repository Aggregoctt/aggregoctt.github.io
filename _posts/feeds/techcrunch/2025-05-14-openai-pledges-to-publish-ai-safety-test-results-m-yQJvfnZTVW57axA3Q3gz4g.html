---
author: Kyle Wiggers
canonical_url: https://techcrunch.com/2025/05/14/openai-pledges-to-publish-ai-safety-test-results-more-often/
date: '2025-05-14T16:38:40'
excerpt: OpenAI is moving to publish the results of its internal AI model safety evaluations
  more regularly in what the outfit is saying is an effort to increase transparency.
  On Wednesday, OpenAI launched the Safety evaluations hub, a web page showing how
  the company&#8217;s models score on various tests for harmful content generation,
  jailbreaks, and hallucinations. [&#8230;]
image: assets/media/yQJvfnZTVW57axA3Q3gz4g-nk-Mcgrx6-SN-s7J2YPOxw.webp
source: techcrunch
tags:
- AI
- Safety
- OpenAI
title: OpenAI pledges to publish AI safety test results more often
---
<div>
<p id="speakable-summary" class="wp-block-paragraph">OpenAI is moving to publish the results of its internal AI model safety evaluations more regularly in what the outfit is saying is an effort to increase transparency.</p>

<p class="wp-block-paragraph">On Wednesday, OpenAI launched the <a href="https://openai.com/safety/evaluations-hub/" target="_blank" rel="noreferrer noopener nofollow">Safety evaluations hub</a>, a web page showing how the company&#8217;s models score on various tests for harmful content generation, jailbreaks, and hallucinations. OpenAI says that it&#8217;ll use the hub to share metrics on an &#8220;ongoing basis&#8221; and that it intends to update the hub with &#8220;major model updates&#8221; going forward.</p>

 

<p class="wp-block-paragraph">&#8220;As the science of AI evaluation evolves, we aim to share our progress on developing more scalable ways to measure model capability and safety,&#8221; wrote OpenAI in a <a href="https://openai.com/safety/evaluations-hub/" target="_blank" rel="noreferrer noopener nofollow">blog post</a>. &#8220;By sharing a subset of our safety evaluation results here, we hope this will not only make it easier to understand the safety performance of OpenAI systems over time, but also support community efforts&#8288; to increase transparency across the field.&#8221;</p>

 


 


<p class="wp-block-paragraph">OpenAI says that it may add additional evaluations to the hub over time. </p>

<p class="wp-block-paragraph">In recent months, OpenAI has raised the ire of some ethicists for&#160;<a href="https://www.ft.com/content/8253b66e-ade7-4d1f-993b-2d0779c7e7d8" target="_blank" rel="noreferrer noopener nofollow">reportedly</a>&#160;rushing the safety testing of certain flagship models and&#160;<a href="https://techcrunch.com/2025/04/15/openai-ships-gpt-4-1-without-a-safety-report/">failing to release technical reports for others</a>. The company&#8217;s CEO, Sam Altman, also&#160;<a href="https://techcrunch.com/2025/03/29/sam-altman-firing-drama-detailed-in-new-book-excerpt/">stands accused</a>&#160;of misleading OpenAI executives about model safety reviews prior to his&#160;<a href="https://techcrunch.com/2023/11/17/sam-altman-is-out-as-openais-ceo/">brief ouster</a>&#160;in November 2023.</p>

<p class="wp-block-paragraph">Late last month, OpenAI was <a href="https://techcrunch.com/2025/04/29/openai-rolls-back-update-that-made-chatgpt-too-sycophant-y/">forced to roll back an update</a> to the default model powering ChatGPT, GPT-4o, after users began reporting that it responded in an overly validating and agreeable way.&#160;X became flooded with screenshots of ChatGPT applauding all sorts of problematic,&#160;<a href="https://x.com/fabianstelzer/status/1916372374091423984" target="_blank" rel="noreferrer noopener nofollow">dangerous</a>&#160;<a href="https://x.com/thinkbuildnext/status/1916250081579217243" target="_blank" rel="noreferrer noopener nofollow">decisions</a>&#160;and&#160;ideas.</p>

 
 


			

			</div>