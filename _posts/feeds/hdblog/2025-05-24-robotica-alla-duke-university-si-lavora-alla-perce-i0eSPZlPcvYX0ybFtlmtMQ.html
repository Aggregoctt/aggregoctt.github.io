---
author: HDblog.it
canonical_url: https://www.hdblog.it/tecnologia/articoli/n619466/robot-sensori-tatto-duke/
date: '2025-05-24T07:20:00'
excerpt: Robot esploratore riconosce vibrazioni e tocchi per muoversi meglio allâ€™aperto
image: assets/media/i0eSPZlPcvYX0ybFtlmtMQ-SkGiN1I1wvx6mB7tf5JDXw.webp
source: hdblog
tags:
- Tecnologia
title: 'Robotica: alla Duke University si lavora alla percezione del terreno'
---
<div><p>Nel cuore dei laboratori della Duke University, un gruppo di ricercatori ha lavorato un modo interessante con cui<strong><a href="https://www.hdblog.it/robot/"> i robot </a>possono orientarsi in ambienti complessi</strong>. Non si tratta solo di un miglioramento tecnico, ma di un passo in avanti nella percezione sensoriale delle macchine: grazie a una<strong> nuova piattaforma chiamata WildFusion</strong>, un robot quadrupede &#232; ora in grado di &#8220;sentire&#8221; il terreno che calpesta, proprio come farebbe un essere umano.</p>    <p>Fino ad oggi, la stragrande maggioranza dei robot autonomi si &#232; basata esclusivamente su telecamere e sensori LiDAR per raccogliere informazioni sul mondo circostante. Tuttavia, in ambienti naturali o disastrati, questi strumenti si rivelano spesso insufficienti. I percorsi non sono sempre chiari, i punti di riferimento possono mancare e la mappatura tridimensionale diventa difficile in presenza di dati frammentari o disturbati. WildFusion &#232; stato concepito per affrontare proprio queste difficolt&#224;, fondendo una variet&#224; di input sensoriali in un&#8217;unica comprensione spaziale.</p>    <p>Il robot che utilizza questa tecnologia &#232; dotato <strong>non solo di telecamere RGB e sensori LiDAR, ma anche di microfoni da contatto e sensori tattili applicati alle zampe</strong>. I microfoni rilevano le vibrazioni emesse dal terreno durante la camminata, distinguendo tra ghiaia, terra o radici. I sensori tattili, invece, forniscono informazioni sulla pressione esercitata e sull&#8217;inclinazione del corpo del robot, permettendo un costante adattamento alla superficie.</p>    <p>Tutti questi segnali vengono elaborati da un modello di apprendimento profondo, basato su rappresentazioni neurali implicite, che <strong>traduce i dati raccolti in una visione fluida e coerente dello spazio</strong>. Il risultato? Il robot &#232; capace di <strong>scegliere in modo autonomo e istintivo i percorsi migliori, anche quando la vista non &#232; sufficiente.</strong></p>    <p>Il sistema &#232; stato messo alla prova nei paesaggi variegati del parco statale Eno River, nella Carolina del Nord. Tra vegetazione fitta, sentieri irregolari e aree di ghiaia, WildFusion ha permesso al robot di muoversi in sicurezza, migliorando sensibilmente la sua capacit&#224; di prevedere la percorribilit&#224; del terreno. Per i ricercatori &#232; stata una prova di grande soddisfazione: vederlo avanzare con sicurezza in un ambiente naturale &#232; stato un segnale tangibile dell&#8217;efficacia della loro tecnologia.</p>    <p>Il potenziale applicativo di WildFusion &#232; vasto. Dalle missioni di ricerca e soccorso in scenari pericolosi alle ispezioni in zone inaccessibili per l&#8217;uomo, questo sistema potrebbe rendere l&#8217;automazione molto pi&#249; flessibile e utile nella realt&#224;. Resta tuttavia fondamentale discutere anche le implicazioni etiche legate all&#8217;uso di robot autonomi in contesti delicati. La trasparenza e il controllo umano rimangono centrali per evitare abusi o impieghi inappropriati.</p>    <p>Il progetto, presentato ufficialmente all&#8217;IEEE International Conference on Robotics and Automation (ICRA 2025) ad Atlanta, rappresenta un significativo avanzamento nella robotica mobile. L&#8217;integrazione sensoriale e la capacit&#224; di adattamento potrebbero diventare standard nel prossimo futuro, rendendo i <strong>robot pi&#249; consapevoli dell&#8217;ambiente in cui operano</strong>, non solo visivamente, ma anche fisicamente.</p></div>