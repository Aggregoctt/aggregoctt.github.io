---
author: HDblog.it
canonical_url: https://www.hdblog.it/sicurezza/articoli/n618715/xai-chatbot-polemica-grok-allucinazioni/
date: '2025-05-16T14:25:00'
excerpt: 'Grok di xAI parla di genocidio bianco per ore: era una modifica non autorizzata'
image: assets/media/OV79A14ONFTqjBRUQkP9Uw-rog00XS8OpthXDdhJPLIJg.webp
source: hdblog
tags:
- Sicurezza
title: 'Grok e la folle teoria del genocidio bianco: errore umano dietro le uscite
  del chatbot'
---
<div><p>Il chatbot <a href="https://www.hdblog.it/grok-ai/">Grok di xAI</a>, la societ&#224; guidata da <a href="https://www.hdblog.it/elon-musk/">Elon Musk</a>, &#232; tornato sotto i riflettori per alcuni motivi imbarazzanti, parliamo di particolari "allucinazioni" che non sono passate inosservate. Per diverse ore, nella giornata di mercoled&#236;, l&#8217;AI ha diffuso <a href="https://www.hdblog.it/internet/articoli/n618567/grok-twitter-genocidio-bianco/">contenuti incentrati sulla teoria del &#8220;genocidio bianco&#8221;</a> in Sudafrica, introducendo questo tema in risposte scollegate tra loro e, in alcuni casi, del tutto surreali.</p>    <p>Secondo quanto riferito dalla stessa xAI, alla base del comportamento anomalo c&#8217;&#232; stata<strong> una &#8220;modifica non autorizzata&#8221; del prompt di sistema di Grok, ovvero l&#8217;insieme di istruzioni fondamentali che guidano le risposte del modello</strong>. La societ&#224; ha precisato che tale intervento contraddiceva le politiche interne e i valori fondamentali del gruppo. In risposta, &#232; stata avviata un&#8217;indagine interna che ha portato a una serie di contromisure. Ecco il post che conferma quanto scritto.</p><p>Tra le nuove azioni adottate spiccano la decisione di pubblicare su GitHub i prompt di sistema di Grok, per garantire maggiore trasparenza, l&#8217;istituzione di un team di monitoraggio attivo 24 ore su 24 e l&#8217;introduzione di restrizioni pi&#249; severe che impediscano ai dipendenti di modificare i prompt senza una revisione approvata.</p>    <p>Ma cosa &#232; successo nello specifico? L&#8217;episodio di mercoled&#236; &#232; stato caratterizzato da<strong> una serie di risposte assurde da parte di Grok</strong>: dalla menzione dei contadini bianchi sudafricani in risposta a un video di un gatto che beve, fino a improbabili riferimenti al brano &#8220;Kill the Boer&#8221; durante una conversazione su Spongebob. Il tono utilizzato, talvolta caricaturale, ha suscitato ulteriori perplessit&#224;. Persino Sam Altman, CEO di OpenAI e rivale diretto di xAI, ha ironizzato pubblicamente sullo scivolone del chatbot.</p><p>Non si tratta del primo caso in cui la responsabilit&#224; di un comportamento scorretto di Grok viene attribuita a un singolo individuo. <strong>Gi&#224; a febbraio, xAI aveva accusato un ex dipendente proveniente da <a href="https://www.hdblog.it/openai/">OpenAI </a></strong>di aver alterato i prompt per escludere contenuti critici nei confronti di Elon Musk e Donald Trump, senza che alcun responsabile interno ne fosse stato informato. Anche allora, le dichiarazioni ufficiali parlavano di &#8220;azioni non autorizzate&#8221; e di una vulnerabilit&#224; nel sistema di controllo interno.</p></div>