---
author: HDblog.it
canonical_url: https://www.hdblog.it/sicurezza/articoli/n618705/fbi-truffa-audio-deepfake/
date: '2025-05-16T12:51:00'
excerpt: I consigli non bastano.
image: assets/media/K5TCb11D89n0YkD61OjQEw-nVpWp71-ecepss-fpmK0PA.webp
source: hdblog
tags:
- Sicurezza
title: FBI avverte di una truffa deepfake in corso che sfrutta figure governative
---
<div><p>Il problema dei <a href="https://www.hdblog.it/deepfake/">deepfake</a> sta diventando molto serio considerando l'avanzamento dell'<a href="https://www.hdblog.it/ia/">intelligenza artificiale</a>. <a href="https://www.hdblog.it/sicurezza/articoli/n618441/deepfake-giornalista-rai-vaccini/">Di recente ha colpito anche l'Italia</a>, poich&#233; una giornalista Rai si &#232; ritrovata a prestare il volto, involontariamente, ad <a href="https://www.hdblog.it/sicurezza/articoli/n618441/deepfake-giornalista-rai-vaccini/">una truffa a sfondo farmaceutico</a>. Adesso per&#242; ci spostiamo oltre il nostro Paese, con un monito che arriva direttamente dall&#8217;FBI: l'agenzia invita a <strong>prestare attenzione a una campagna di messaggistica dannosa in corso</strong> che sfrutta <strong>audio generato dall&#8217;AI per impersonare funzionari governativi</strong>, nel tentativo di indurre i destinatari a cliccare su link in grado di <a href="https://www.hdblog.it/truffe-e-raggiri/">infettare i loro computer</a>. L'avviso recita quanto segue:</p>

<blockquote>
<p>Da aprile 2025, attori malintenzionati hanno impersonato alti funzionari statunitensi per prendere di mira individui, molti dei quali sono attuali o ex funzionari di alto livello del governo federale o statale USA e i loro contatti. Se ricevete un messaggio che afferma di provenire da un alto funzionario USA, non date per scontata la sua autenticit&#224;.</p>
</blockquote><p>I creatori della campagna inviano messaggi vocali generati dall'AI, meglio conosciuti come deepfake, insieme a messaggi di testo &#8220;nel tentativo di creare un rapporto di fiducia prima di ottenere l&#8217;accesso ad account personali&#8221;, spiegano i funzionari dell&#8217;FBI. I deepfake utilizzano l&#8217;AI per imitare la voce e le caratteristiche di parlato di un individuo specifico. <strong>Le differenze tra la voce autentica e quella simulata sono spesso indistinguibili senza un&#8217;analisi esperta</strong>.</p>    <p>Un modo per ottenere accesso ai dispositivi delle vittime consiste nel chiedere se la conversazione possa continuare su un&#8217;altra piattaforma di messaggistica e poi convincere con successo la vittima a cliccare su un link malevolo sostenendo che consentir&#224; di utilizzare la piattaforma alternativa.</p>

<p>Per quanto possano essere utili, le indicazioni non tengono conto di alcune sfide che i bersagli di queste truffe devono affrontare. Spesso, i<strong> truffatori creano un senso di urgenza affermando che esista un&#8217;emergenza in corso che richiede una risposta immediata</strong>. </p>    <p>In pi&#249;,<strong> le tecniche di truffa che sfruttano l&#8217;intelligenza artificiale si evolvono e migliorano di giorno in giorno</strong>, rendendo sempre pi&#249; difficile distinguere ci&#242; che &#232; vero da ci&#242; che &#232; falso. Non esiste una soluzione magica per difendersi da questo tipo di truffe. Ammettere che nessuno &#232; immune dall&#8217;essere ingannato &#232; fondamentale per potersi proteggere. Di conseguenza, per proteggersi efficacemente, i<strong> sistemi di difesa e identificazione non devono limitarsi a correre dietro alle nuove minacce, ma restare costantemente un passo avanti rispetto ai truffatori</strong>. Investire in tecnologie avanzate di autenticazione, formazione continua e collaborazione tra autorit&#224;, aziende e utenti &#232; fondamentale per garantire che la sicurezza anticipi e neutralizzi le strategie malevole basate sull&#8217;AI.</p></div>